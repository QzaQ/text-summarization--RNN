{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Pointer Generator network for document summarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:24.833524Z",
     "iopub.status.busy": "2023-08-21T10:02:24.833115Z",
     "iopub.status.idle": "2023-08-21T10:02:24.848118Z",
     "shell.execute_reply": "2023-08-21T10:02:24.846789Z",
     "shell.execute_reply.started": "2023-08-21T10:02:24.833492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import utils and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "from typing import Callable, Optional\n",
    "from copy import deepcopy\n",
    "\n",
    "# Import pytoch libraries and modules \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "#Import libraries for text procesing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import specific libraries for metrics evaluation and plotting progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:24.935933Z",
     "iopub.status.busy": "2023-08-21T10:02:24.935642Z",
     "iopub.status.idle": "2023-08-21T10:02:31.800382Z",
     "shell.execute_reply": "2023-08-21T10:02:31.799383Z",
     "shell.execute_reply.started": "2023-08-21T10:02:24.935904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pkbar in /opt/conda/lib/python3.7/site-packages (0.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pkbar) (1.18.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pkbar\n",
    "import pkbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:31.803902Z",
     "iopub.status.busy": "2023-08-21T10:02:31.803433Z",
     "iopub.status.idle": "2023-08-21T10:02:39.147555Z",
     "shell.execute_reply": "2023-08-21T10:02:39.146489Z",
     "shell.execute_reply.started": "2023-08-21T10:02:31.803848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in /opt/conda/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from rouge) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Class to store all the parameters in the code\n",
    "\n",
    "This is a optimal way to store and access the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.150645Z",
     "iopub.status.busy": "2023-08-21T10:02:39.150237Z",
     "iopub.status.idle": "2023-08-21T10:02:39.163895Z",
     "shell.execute_reply": "2023-08-21T10:02:39.162922Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.150602Z"
    }
   },
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "  # Model Parameters\n",
    "  hidden_size: int = 150  # of the encoder; default decoder size is doubled if encoder is bidi\n",
    "  dec_hidden_size: Optional[int] = 200  # if set, a matrix will transform enc state into dec state\n",
    "  embed_size: int = 100 # Size of the embedding vectors\n",
    "  eps=1e-31\n",
    "  batch_size=16 \n",
    "  enc_bidi = True #Set the encoder as bidirectional\n",
    "  enc_rnn_dropout = 0.1 # Set the dropout parameter in the encoder\n",
    "  enc_attn = True #Activate the encoder attention\n",
    "  dec_attn = True #Activate the decoder attention\n",
    "  pointer = True #Activate the pointer generator mechanism\n",
    "  # Set different dropout probabilities in the decoder\n",
    "  dec_in_dropout=0.1\n",
    "  dec_rnn_dropout=0.1\n",
    "  dec_out_dropout=0.1\n",
    "  # Vocabulary and data parameters\n",
    "  max_src_len: int = 65  # exclusive of special tokens such as EOS\n",
    "  max_tgt_len: int = 15  # exclusive of special tokens such as EOS\n",
    "  vocab_min_frequency: int = 3\n",
    "  # Data paths\n",
    "  embed_file: Optional[str] = '/kaggle/input/d/danielwillgeorge/glove6b100dtxt/glove.6B.100d.txt'  # use pre-trained embeddings\n",
    "  data_path: str = '/kaggle/input/cleaned-news-summary/cl_train_news_summary_more.csv'\n",
    "  val_data_path: Optional[str] = '/kaggle/input/cleaned-news-summary/cl_train_news_summary_more.csv'\n",
    "  test_data_path: str = '/kaggle/input/cleaned-news-summary/cl_valid_news_summary_more.csv'\n",
    "  # Parameters to save the model\n",
    "  resume_train = False\n",
    "  encoder_weights_path='encoder_sum.pt'\n",
    "  decoder_weights_path='decoder_sum.pt'\n",
    "  encoder_decoder_adapter_weights_path='adapter_sum.pt'\n",
    "  losses_path='val_losses.pkl'\n",
    "  print_every = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function will be used to tokenize the texts. If we want to apply another moethod we only need to change this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.165750Z",
     "iopub.status.busy": "2023-08-21T10:02:39.165391Z",
     "iopub.status.idle": "2023-08-21T10:02:39.173256Z",
     "shell.execute_reply": "2023-08-21T10:02:39.172113Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.165706Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_tokenizer(text, lower=False, newline=None):\n",
    "  if lower:\n",
    "    text = text.lower()\n",
    "  if newline is not None:  # replace newline by a token\n",
    "    text = text.replace('\\n', ' ' + newline + ' ')\n",
    "  return text.split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and create the vocabularies\n",
    "\n",
    "Now we create a Vocab (vocabulary) Class to store the vocabulary, the mapping between words and its numeric representation and functions to add words and sentences to the vocabulary. There is also some function to transform a word to its vector representation and to transform the representation to a Torch tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.178164Z",
     "iopub.status.busy": "2023-08-21T10:02:39.177844Z",
     "iopub.status.idle": "2023-08-21T10:02:39.199396Z",
     "shell.execute_reply": "2023-08-21T10:02:39.198602Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.178136Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "  PAD = 0\n",
    "  SOS = 1\n",
    "  EOS = 2\n",
    "  UNK = 3\n",
    "\n",
    "  def __init__(self):\n",
    "    ''' Initialize the structuresto store the information about the vocabulary'''\n",
    "    self.word2index = {}\n",
    "    self.word2count = Counter()\n",
    "    self.reserved = ['<PAD>', '<SOS>', '<EOS>', '<UNK>']\n",
    "    self.index2word = self.reserved[:]\n",
    "    self.embeddings = None\n",
    "\n",
    "  def add_words(self, words):\n",
    "    ''' Add words to the vocabulary'''\n",
    "    for word in words:\n",
    "      #if it is an unseen word  \n",
    "      if word not in self.word2index:\n",
    "        #Include the word in the mapping from word to index\n",
    "        self.word2index[word] = len(self.index2word)\n",
    "        # Include the word in the indexes\n",
    "        self.index2word.append(word)\n",
    "    # Increment the count of ocurrencies of the word to 1\n",
    "    self.word2count.update(words)\n",
    "  \n",
    "  def load_embeddings(self, file_path: str, dtype=np.float32) -> int:\n",
    "    ''' Load the embedding vectors from a file into the vocabulary'''\n",
    "    num_embeddings = 0\n",
    "    vocab_size = len(self)\n",
    "    with open(file_path, 'rb') as f:\n",
    "      # For every word in the embedding vectors\n",
    "      for line in f:\n",
    "        line = line.split()\n",
    "        word = line[0].decode('utf-8')\n",
    "        # self.add_words([word])\n",
    "        # Get the index of the embedded word\n",
    "        idx = self.word2index.get(word)\n",
    "        if idx is not None:\n",
    "          # Extract the embedding vector of the word\n",
    "          vec = np.array(line[1:], dtype=dtype)\n",
    "          #If the embedding vector is not initialized\n",
    "          if self.embeddings is None:\n",
    "            # Set the embeddings dimension, initialize the embedding vector to zeros\n",
    "            n_dims = len(vec)\n",
    "            self.embeddings = np.random.normal(np.zeros((vocab_size, n_dims))).astype(dtype)\n",
    "            self.embeddings[self.PAD] = np.zeros(n_dims)\n",
    "          # Store the embedding in the array of embeddings \n",
    "          self.embeddings[idx] = vec          \n",
    "          num_embeddings += 1\n",
    "    return num_embeddings\n",
    "\n",
    "  def save_to_file(self, filename):\n",
    "    ''' Save the Vocab object to a file'''\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(self,f) \n",
    "\n",
    "  def __getitem__(self, item):\n",
    "    ''' Get the next item when iterating over the instance'''\n",
    "    if type(item) is int:\n",
    "      return self.index2word[item]\n",
    "    return self.word2index.get(item, self.UNK)\n",
    "\n",
    "  def __len__(self):\n",
    "    ''' Return the length of the instance or vocabulary'''\n",
    "    return len(self.index2word)\n",
    "\n",
    "\n",
    "def load_vocab(filename):\n",
    "    ''' Load a Vocab instance from a file'''\n",
    "    with open(filename,'rb') as f:\n",
    "        v = pickle.load(f)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.203153Z",
     "iopub.status.busy": "2023-08-21T10:02:39.202613Z",
     "iopub.status.idle": "2023-08-21T10:02:39.225306Z",
     "shell.execute_reply": "2023-08-21T10:02:39.224267Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.203115Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "  ''' Create a Class to store the data input and its features'''\n",
    "  def __init__(self, filename: str, tokenize: Callable=simple_tokenizer, max_src_len: int=None,\n",
    "               max_tgt_len: int=None, max_rows: int=None, truncate_src: bool=False, truncate_tgt: bool=False):\n",
    "    print(\"Reading dataset %s...\" % filename, end=' ', flush=True)\n",
    "    # Save the filename and initialize the variables\n",
    "    self.filename = filename\n",
    "    self.pairs = []\n",
    "    self.src_len = 0\n",
    "    self.tgt_len = 0\n",
    "    self.max_rows = max_rows\n",
    "\n",
    "    #Read the csv file, using max rows if it is defined\n",
    "    if max_rows is None:\n",
    "        df = pd.read_csv(filename, encoding='utf-8')\n",
    "    else:\n",
    "        df = pd.read_csv(filename, encoding='utf-8', nrows=max_rows\n",
    "                        )\n",
    "    # Tokenize the source texts\n",
    "    sources = df['text'].apply(lambda x : tokenize(x))\n",
    "    # Truncate the sources texts\n",
    "    if truncate_src:\n",
    "        sources = [src[:max_src_len] if len(src)>max_src_len else src for src in sources]\n",
    "    # Tokenize the targets\n",
    "    targets = df['summary'].apply(lambda x : tokenize(x))\n",
    "    # Trucate the targets\n",
    "    if truncate_tgt:\n",
    "        targets = [tgt[:max_tgt_len] if len(tgt)>max_tgt_len else tgt for tgt in targets]\n",
    "        \n",
    "    # Calculate the length of every source and targets        \n",
    "    src_length = [len(src)+1 for src in sources]\n",
    "    tgt_length = [len(tgt)+1 for tgt in targets]\n",
    "    #Calculate the max length of the sources and the targets\n",
    "    max_src = max(src_length)\n",
    "    max_tgt = max(tgt_length)\n",
    "    #Create a tuple contaiing source,target,source length, target length\n",
    "    self.src_len = max_src\n",
    "    self.tgt_len = max_tgt\n",
    "    # Insert the source text and target in the pairs class atribute\n",
    "    self.pairs.append([(src, tgt, src_len, tgt_len) for src,tgt,src_len,tgt_len in zip(sources,targets,src_length,tgt_length)])\n",
    "    self.pairs = self.pairs[0]\n",
    "    print(\"%d pairs.\" % len(self.pairs))\n",
    "\n",
    "  def build_vocab(self, min_freq, embed_file: str=None) -> Vocab:\n",
    "    ''' Build the vocabulary extracted from the texts in the object class\n",
    "        Input:\n",
    "        - min_freq: integer, minimum ocurrencies needed to include the word in the vocab\n",
    "        - embed_file: string, path + filename of the embeddings file\n",
    "    '''\n",
    "    # Extract the words in the whole corpus\n",
    "    total_words=[src+tgr for src,tgr,len_src,len_tgr in self.pairs]\n",
    "    total_words = [item for sublist in total_words for item in sublist]\n",
    "    # Create a counter to count the ocurrencies of every word in the corpus\n",
    "    word_counts = Counter(total_words)\n",
    "    # Create a vocabulary object\n",
    "    vocab=Vocab()\n",
    "    for word,count in word_counts.items():\n",
    "        # If occurencies of the word are bigger then min_freq\n",
    "        if(count>min_freq):\n",
    "            # Include the cord in the vocabulary\n",
    "            vocab.add_words([word])  \n",
    "    # Load the embeddings in the vocab object\n",
    "    count = vocab.load_embeddings(embed_file)\n",
    "    print(\"%d pre-trained embeddings loaded.\" % count)\n",
    "\n",
    "    return vocab  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a Class to contain our Dataset, it will simplified how the training process work with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.227434Z",
     "iopub.status.busy": "2023-08-21T10:02:39.226885Z",
     "iopub.status.idle": "2023-08-21T10:02:39.238564Z",
     "shell.execute_reply": "2023-08-21T10:02:39.237204Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.227391Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(nn.Module):\n",
    "    ''' A Dataset Class where we store all the data needed during the training phase'''\n",
    "    \n",
    "    def __init__(self, src_sents, trg_sents, vocab):\n",
    "      '''Initialize the instance and store the source texts, targets or summaries '''\n",
    "      self.src_sents = src_sents\n",
    "      self.trg_sents = trg_sents\n",
    "      self.vocab=vocab\n",
    "      # Keep track of how many data points.\n",
    "      self._len = len(src_sents)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ''' Return the ith items from the object\n",
    "            Input:\n",
    "            - Index: integer, index of the items to return\n",
    "            Output:\n",
    "            - a dictionary with keys x the source texts, y the targets, \n",
    "              x_len length of source texts, y_len the length of targets\n",
    "        '''\n",
    "        return {'x':self.src_sents[index], \n",
    "                'y':self.trg_sents[index], \n",
    "                'x_len':len(self.src_sents[index]), \n",
    "                'y_len':len(self.trg_sents[index])}\n",
    "    \n",
    "    def __len__(self):\n",
    "        ''' Return the length of the object'''\n",
    "        return self._len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define some helper functions to create the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.240613Z",
     "iopub.status.busy": "2023-08-21T10:02:39.240195Z",
     "iopub.status.idle": "2023-08-21T10:02:39.259890Z",
     "shell.execute_reply": "2023-08-21T10:02:39.259108Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.240576Z"
    }
   },
   "outputs": [],
   "source": [
    "def tensorize(vocab, tokens):\n",
    "    ''' Convert the tokens received to a tensor '''\n",
    "    return torch.tensor([vocab[token] for token in tokens])\n",
    "\n",
    "def pad_sequence(vectorized_sent, max_len):\n",
    "    ''' Padding the sentence (tensor) to max_len '''\n",
    "    pad_dim = (0, max_len - len(vectorized_sent))\n",
    "    return F.pad(vectorized_sent, pad_dim, 'constant').tolist()\n",
    "\n",
    "def preprocess(x,y,p,vocab):\n",
    "    ''' Prepare a source text x and a target summary y: convert them to tensors,\n",
    "        pads the sentences to its max length.\n",
    "    '''\n",
    "    # Convert x and y to tensors using the vocabulary\n",
    "    tensors_src = tensorize(vocab, x)\n",
    "    tensors_trg = tensorize(vocab, y) \n",
    "    # Return the padded sequence of x and y and its length\n",
    "    return {'x':pad_sequence(tensors_src, p.max_src_len), #¿max_source_len?\n",
    "          'y':pad_sequence(tensors_trg, p.max_tgt_len), #¿,ax_target_len?\n",
    "          'x_len':len(tensors_src), \n",
    "          'y_len':len(tensors_trg)}\n",
    "\n",
    "def sort_batch_by_len(data_dict,p,vocab):\n",
    "    ''' Return a batch of sentences processed and ordered by its length\n",
    "    '''\n",
    "    data=[]\n",
    "    res={'x':[],'y':[],'x_len':[],'y_len':[]}\n",
    "    # For every x and y in the data input\n",
    "    for i in range(data_dict['x_len']):\n",
    "        # Preprocess and tokenize the x and y\n",
    "        data.append(preprocess(data_dict['x'][i],data_dict['y'][i],p,vocab))\n",
    "    # For every preprocessed text, recreate the x and y lists\n",
    "    for i in range(len(data)):\n",
    "        res['x'].append(data[i]['x'])\n",
    "        res['y'].append(data[i]['y'])\n",
    "        res['x_len'].append(len(data[i]['x']))\n",
    "        res['y_len'].append(len(data[i]['y']))  \n",
    "    \n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(res['x_len']).argsort()[::-1].tolist()\n",
    "    # Create a batch of data ordered by its length\n",
    "    data_batch = {name:[_tensor[i] for i in sorted_indices]\n",
    "                  for name, _tensor in res.items()}\n",
    "    return data_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.261819Z",
     "iopub.status.busy": "2023-08-21T10:02:39.261384Z",
     "iopub.status.idle": "2023-08-21T10:02:39.276325Z",
     "shell.execute_reply": "2023-08-21T10:02:39.275342Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.261782Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "  ''' Define an encoder in a seq2seq architecture'''\n",
    "  def __init__(self, embed_size, hidden_size, bidi=True, rnn_drop: float=0):\n",
    "    super(EncoderRNN, self).__init__()\n",
    "    # Set the hidden size\n",
    "    self.hidden_size = hidden_size\n",
    "    # Activate bidirectional mode\n",
    "    self.num_directions = 2 if bidi else 1\n",
    "    # Define the GRU layer of the encoder\n",
    "    self.gru = nn.GRU(embed_size, hidden_size, bidirectional=bidi, dropout=rnn_drop)\n",
    "\n",
    "  def forward(self, embedded,hidden,input_lengths=None):\n",
    "    ''' Run a Forward pass of the encoder to return outputs\n",
    "        Input:\n",
    "        - embedded: tensor, the embedding of the input data (word of the soure text)\n",
    "        - hidden: a tensor, the previous hidden state of the encoder\n",
    "        - input:lengths: a list of integers, length of the inputs \n",
    "    '''\n",
    "    # Pack the padded sequence of the embedded input\n",
    "    if input_lengths is not None:\n",
    "      embedded = pack_padded_sequence(embedded, input_lengths,batch_first=True)\n",
    "    \n",
    "    # Apply the GRU layer of the encoder\n",
    "    output, hidden = self.gru(embedded,hidden)\n",
    "    \n",
    "    # Pad the sequence output\n",
    "    if input_lengths is not None:\n",
    "      output, _ = pad_packed_sequence(output)\n",
    "    # If bidirectional\n",
    "    if self.num_directions > 1:\n",
    "      # Transform the hidden state tensor  \n",
    "      # hidden: (num directions, batch, hidden) => (1, batch, hidden * 2)\n",
    "      batch_size = hidden.size(1)\n",
    "      hidden = hidden.transpose(0, 1).contiguous().view(1, batch_size,\n",
    "                                                        self.hidden_size * self.num_directions)\n",
    "    return output, hidden\n",
    "\n",
    "  def init_hidden(self, batch_size, device):\n",
    "    ''' Initialize the hidden state of the encoder to zeros: num_directions, batch size, hidden size '''\n",
    "    return torch.zeros(self.num_directions, batch_size, self.hidden_size, device=device) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.280012Z",
     "iopub.status.busy": "2023-08-21T10:02:39.279728Z",
     "iopub.status.idle": "2023-08-21T10:02:39.316885Z",
     "shell.execute_reply": "2023-08-21T10:02:39.316054Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.279985Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "  ''' Define a decoder with atention in a seq2seq architecture'''\n",
    "  def __init__(self, vocab_size, embed_size, hidden_size, enc_attn=True, dec_attn=True,\n",
    "               enc_attn_cover=True, pointer=True,\n",
    "               in_drop: float=0, rnn_drop: float=0, out_drop: float=0, enc_hidden_size=None,\n",
    "               epsilon: float=0.0, device: str=\"cpu\"):\n",
    "    ''' Initialize the decoder instance defining its parameters:\n",
    "            Input:\n",
    "                - vocab_size: integer, number of words in the vocabulary \n",
    "                - embed_size: integer, size of the embedding layer\n",
    "                - hidden_size: integer, size of the hidden layer (Hyperparameter)\n",
    "                - enc_attn: activate the attention in the encoder\n",
    "                - dec_attn: activate the attention in the decoder\n",
    "                - enc_attn_cover: activate the coverage mechanism in the attention\n",
    "                - pointer: activate the pointer generation\n",
    "                - in_drop: dropout probability to apply to the input of the decoder\n",
    "                - rnn_drop: dropout probability to apply to the GRU layer of the decoder\n",
    "                - out_drop: dropout probability to apply to the output of the decoder\n",
    "                - enc_hidden_size: dimension if the hidden state of the encoder\n",
    "                - epsilon: float\n",
    "                - device: cpu or gpu, device to store the tensors\n",
    "    '''\n",
    "\n",
    "    super(DecoderRNN, self).__init__()\n",
    "    # Set the attibutes\n",
    "    self.vocab_size = vocab_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.combined_size = hidden_size\n",
    "    self.device = device\n",
    "    self.eps = epsilon\n",
    "    # Define the input dropout layer \n",
    "    self.in_drop = nn.Dropout(in_drop) if in_drop > 0 else None\n",
    "    # Define the GRU layer\n",
    "    self.gru = nn.GRU(embed_size, hidden_size, dropout=rnn_drop)\n",
    "    \n",
    "    # Set the hidden size of the encoder to the hidden size of the decoder if it is not defined\n",
    "    if not enc_hidden_size: enc_hidden_size = self.hidden_size\n",
    "    # Bilinear layer of the encoder\n",
    "    self.enc_bilinear = nn.Bilinear(hidden_size, enc_hidden_size, 1)\n",
    "    \n",
    "    self.combined_size += enc_hidden_size\n",
    "    if enc_attn_cover:\n",
    "      # Initialize the weights of the coverage mechanism\n",
    "      self.cover_weight = nn.Parameter(torch.rand(1))\n",
    "\n",
    "    # Bilinear layer of the encoder\n",
    "    self.dec_bilinear = nn.Bilinear(self.hidden_size, self.hidden_size, 1)\n",
    "    self.combined_size += self.hidden_size\n",
    "    \n",
    "    # Define the output dropout layer\n",
    "    self.out_drop = nn.Dropout(out_drop) if out_drop > 0 else None\n",
    "    # Define the pointer generator layer\n",
    "    self.ptr = nn.Linear(self.combined_size, 1)\n",
    "\n",
    "    # Define the linear layer at the output\n",
    "    self.out = nn.Linear(self.combined_size, vocab_size)\n",
    "\n",
    "  def forward(self, embedded, hidden, encoder_hidden=None, decoder_states=None, coverage_vector=None, *,\n",
    "              encoder_word_idx=None, ext_vocab_size: int=None, log_prob: bool=True):\n",
    "    ''' Run a Forward pass of the decoder to return outputs\n",
    "        Input:\n",
    "        - embedded: tensor, the embedding of the input data (decoder output in the last step\n",
    "        - hidden: a tensor, the previous hidden state of the decoder\n",
    "        - decoder_states: tensor, hidden state of the decoder in the last step\n",
    "        - coverage_vector: tensor, coverage vector at this step\n",
    "        - encoder_word_idx: tensor, indexes of the words in the source text\n",
    "        - ext_vocab_size: integer, vocabulary size of the extended vocabulary\n",
    "        - log_prob: bool, use of Log Softmax or Softmax in the output\n",
    "    '''\n",
    "    #print('Self Dev:',self.device)\n",
    "    # Set the batch sze and initialize the combined context vectors\n",
    "    batch_size = embedded.size(0)\n",
    "    combined = torch.zeros(batch_size, self.combined_size, device=self.device)\n",
    "    # Apply the dropout layer to the input data\n",
    "    if self.in_drop: embedded = self.in_drop(embedded)\n",
    "    # Apply the GRU layer\n",
    "    output, hidden = self.gru(embedded.unsqueeze(0), hidden)  # unsqueeze and squeeze are necessary\n",
    "    combined[:, :self.hidden_size] = output.squeeze(0)        # as RNN expects a 3D tensor (step=1)\n",
    "    offset = self.hidden_size\n",
    "    enc_attn, prob_ptr = None, None  # for visualization\n",
    "\n",
    "    # Set the encoder steps and total size\n",
    "    num_enc_steps = encoder_hidden.size(0)\n",
    "    enc_total_size = encoder_hidden.size(2)\n",
    "    #print('Encoder hidden: ', encoder_hidden.shape,' Hidden: ', hidden.shape)\n",
    "    # Apply the Bilinear layer\n",
    "    enc_attn = self.enc_bilinear(hidden.expand(num_enc_steps, batch_size, -1).contiguous(),encoder_hidden)\n",
    "    # print(hidden.shape,hidden.expand(num_enc_steps, batch_size, -1).shape,encoder_hidden.shape,enc_attn.shape)\n",
    "    \n",
    "    # Update the attention weigths\n",
    "    if coverage_vector is not None:\n",
    "        enc_attn += self.cover_weight * torch.log(coverage_vector.transpose(0, 1).unsqueeze(2) + self.eps)\n",
    "    # Transpose the attention vectors\n",
    "    # transpose => (batch size, num encoder states, 1)\n",
    "    enc_attn = F.softmax(enc_attn, dim=0).transpose(0, 1)\n",
    "    \n",
    "    # Calculate the context vectors \n",
    "    enc_context = torch.bmm(encoder_hidden.permute(1, 2, 0), enc_attn)\n",
    "    # print(enc_context.shape,enc_context.squeeze(2).shape)\n",
    "    \n",
    "    # Update the combined vector with the context vectors \n",
    "    combined[:, offset:offset+enc_total_size] = enc_context.squeeze(2)\n",
    "    offset += enc_total_size\n",
    "    enc_attn = enc_attn.squeeze(2)\n",
    "    \n",
    "    # Set the decoder attention vectors\n",
    "    if decoder_states is not None and len(decoder_states) > 0:\n",
    "      dec_attn = self.dec_bilinear(hidden.expand_as(decoder_states).contiguous(),\n",
    "                                      decoder_states)\n",
    "      dec_attn = F.softmax(dec_attn, dim=0).transpose(0, 1)\n",
    "      dec_context = torch.bmm(decoder_states.permute(1, 2, 0), dec_attn)\n",
    "      combined[:, offset:offset + self.hidden_size] = dec_context.squeeze(2)\n",
    "      offset += self.hidden_size\n",
    "    \n",
    "    # Prepare the data to apply the pointer generator\n",
    "    out_embed = combined\n",
    "    logits = self.out(out_embed)  # (batch size, vocab size)\n",
    "\n",
    "    # Distribute probabilities between generator and pointer\n",
    "    prob_ptr = torch.sigmoid(self.ptr(combined))  # (batch size, 1)\n",
    "    prob_gen = 1 - prob_ptr\n",
    "    # add generator probabilities to output\n",
    "    gen_output = F.softmax(logits, dim=1)  # can't use log_softmax due to adding probabilities\n",
    "    output = prob_gen * gen_output\n",
    "    # Dfine the padding dimension\n",
    "    pad_dim = (0, ext_vocab_size - output.size(1))\n",
    "    # Pad the output tensir\n",
    "    output=F.pad(output, pad_dim, 'constant')\n",
    "\n",
    "    # add pointer probabilities to output\n",
    "    ptr_output = enc_attn\n",
    "    encoder_word_idx_l = encoder_word_idx.long()\n",
    "    # Calculate the output tensor    \n",
    "    try:\n",
    "        output.scatter_add_(1, encoder_word_idx_l, prob_ptr * ptr_output)\n",
    "    except:\n",
    "        prob_po = prob_ptr * ptr_output \n",
    "        print(output.shape,encoder_word_idx_l.shape,prob_ptr.shape, ptr_output.shape, prob_po.shape)\n",
    "        print(output)\n",
    "        print(encoder_word_idx_l)\n",
    "        print(prob_po)\n",
    "        output.scatter_add_(1, encoder_word_idx_l, prob_po)\n",
    "        \n",
    "    # Apply the log in the output\n",
    "    output = torch.log(output + self.eps)\n",
    "\n",
    "    return output, hidden, enc_attn, prob_ptr \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to get the coverage vector from the attention weights of the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.319048Z",
     "iopub.status.busy": "2023-08-21T10:02:39.318391Z",
     "iopub.status.idle": "2023-08-21T10:02:39.326822Z",
     "shell.execute_reply": "2023-08-21T10:02:39.326036Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.318994Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_coverage_vector(enc_attn_weights):\n",
    "    \"\"\"Combine the past attention weights into one vector\"\"\"\n",
    "    coverage_vector = torch.sum(torch.cat(enc_attn_weights), dim=0)\n",
    "    \n",
    "    return coverage_vector  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the steps of the training process\n",
    "\n",
    "First we define a function to get the next batch from the data and the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.328734Z",
     "iopub.status.busy": "2023-08-21T10:02:39.328246Z",
     "iopub.status.idle": "2023-08-21T10:02:39.340502Z",
     "shell.execute_reply": "2023-08-21T10:02:39.339470Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.328693Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next_batch(data, p, vocab, i, batch_size, device):\n",
    "    ''' Generate and return the next batch of the data during training\n",
    "        Input:\n",
    "        - data: list, input data to the model\n",
    "        - p: a class Parameters object, model and training parameters\n",
    "        - vocab: a class Vocab object, vocabulary of the data\n",
    "        - i: integer, index or iterator\n",
    "        - batch_size: integer, batch size\n",
    "        - device: string, where to train the model, cpu or gpu \n",
    "    '''\n",
    "    #Create a copy of the vocabulary\n",
    "    vocab_ext=deepcopy(vocab)\n",
    "\n",
    "    #Get the next batch\n",
    "    try:\n",
    "        data_dict=data[i:i+batch_size]\n",
    "    except:\n",
    "        data_dict=data[i:len(data)]\n",
    "    # Create a batch from an extended cocabulary\n",
    "    data_batch = sort_batch_by_len(data_dict,p,vocab_ext)\n",
    "    # Create an extended cocabulary\n",
    "    for word in data_dict['x']:\n",
    "        vocab_ext.add_words(word)\n",
    "            \n",
    "    # Create a batch from an extended cocabulary\n",
    "    data_batch_extra=sort_batch_by_len(data_dict,p,vocab_ext)\n",
    "    #Create tha inputs in the extended version        \n",
    "    x_extra=torch.tensor(data_batch_extra['x']).to(device)\n",
    "    \n",
    "    # Transform the batch to tensors\n",
    "    x, x_len = torch.tensor(data_batch['x']).to(device), torch.tensor(data_batch['x_len']).to(device)\n",
    "    y, y_len = torch.tensor(data_batch['y']).to(device), torch.tensor(data_batch['y_len']).to(device)\n",
    "\n",
    "    return x, x_len, y, y_len, x_extra, vocab_ext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.342884Z",
     "iopub.status.busy": "2023-08-21T10:02:39.342502Z",
     "iopub.status.idle": "2023-08-21T10:02:39.408215Z",
     "shell.execute_reply": "2023-08-21T10:02:39.407333Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.342827Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataset,val_dataset,vocab,p,embedding_weights, learning_rate, num_epochs):\n",
    "    ''' Run all the steps in the training phase\n",
    "        Input:\n",
    "        - dataset: Dataset object, training data\n",
    "        - val_dataset: Dataset object, validation data\n",
    "        - vocab: a class Vocab object, the vocabulary of the datasets\n",
    "        - p: a class Parameters object, model and training parameters\n",
    "        - embedding_weigths: tensor, the embedding vectors\n",
    "        - learning_rate: float, learning rate parameter\n",
    "        - num_epochs: integer, number of epochs of the training\n",
    "    '''\n",
    "    # Set some variables like eps, batch size and device\n",
    "    eps = p.eps\n",
    "    batch_size =p.batch_size\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    #Create an adapter between encoder hidden state to decoder hidden size \n",
    "    enc_dec_adapter = nn.Linear(p.hidden_size * 2, p.dec_hidden_size).to(DEVICE)\n",
    "    #Create an embedding layer with pretrained weigths\n",
    "    embedding = nn.Embedding(len(vocab), p.embed_size, padding_idx=vocab.PAD,\n",
    "                             _weight=embedding_weights).to(DEVICE)\n",
    "    \n",
    "    # Do not train the embeddings\n",
    "    embedding.weight.requires_grad=False\n",
    "    #Create the encoder\n",
    "    encoder = EncoderRNN(p.embed_size, p.hidden_size, p.enc_bidi,rnn_drop=p.enc_rnn_dropout).to(DEVICE)\n",
    "    #Create the decoder\n",
    "    decoder = DecoderRNN(len(vocab), p.embed_size, p.dec_hidden_size,\n",
    "                                  enc_attn=p.enc_attn, dec_attn=p.dec_attn,\n",
    "                                  pointer=p.pointer,\n",
    "                                  in_drop=p.dec_in_dropout, rnn_drop=p.dec_rnn_dropout,\n",
    "                                  out_drop=p.dec_out_dropout, enc_hidden_size=p.hidden_size * 2,\n",
    "                                  device=DEVICE, epsilon=p.eps).to(DEVICE)\n",
    "    \n",
    "    # If the model components have been training, we restore them from a previous save\n",
    "    if(os.path.exists(p.encoder_weights_path) and p.resume_train):\n",
    "        encoder.load_state_dict(torch.load(p.encoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    if(os.path.exists(p.decoder_weights_path) and p.resume_train):\n",
    "        decoder.load_state_dict(torch.load(p.decoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    if(os.path.exists(p.encoder_decoder_adapter_weights_path) and p.resume_train):   \n",
    "        enc_dec_adapter.load_state_dict(torch.load(p.encoder_decoder_adapter_weights_path,map_location=torch.device(DEVICE)))\n",
    "    \n",
    "    # Create a Dataset class containing the training data\n",
    "    cnn_data=MyDataset([pair[0] for pair in dataset.pairs],[pair[1] for pair in dataset.pairs],vocab)\n",
    "    \n",
    "    # Create a Dataset class containing the validation data\n",
    "    #CHECK IF CREATING A VOCAB FOR VALIDATION IS RIGHT\n",
    "    val_data=MyDataset([pair[0] for pair in val_dataset.pairs],[pair[1] for pair in val_dataset.pairs],vocab)\n",
    "    # print(cnn_data[:3]['x_len'])\n",
    "    \n",
    "    # DEfine the loss function\n",
    "    criterion = nn.NLLLoss(ignore_index=vocab.PAD)\n",
    "    # Define the optimizers for the encoder, decoder and the adapter\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    adapter_optimizer=optim.Adam([{'params':enc_dec_adapter.parameters()}], lr=learning_rate)\n",
    "    # Record the losses\n",
    "    losses=[]\n",
    "    val_losses=[]\n",
    "    #Load the losses from previous trainings\n",
    "    if(os.path.exists(p.losses_path) and p.resume_train):\n",
    "      with open(p.losses_path,'rb') as f:\n",
    "        val_losses=pickle.load(f)\n",
    "        \n",
    "    #Run training for num_epochs\n",
    "    for _e in range(num_epochs):\n",
    "        i=0\n",
    "        #Create a progress bar \n",
    "        print('\\nEpoch: %d/%d' % (_e + 1, num_epochs))\n",
    "        kbar = pkbar.Kbar(target=len(cnn_data), width=8)\n",
    "        #for every batch in the training data \n",
    "        while i<len(cnn_data):\n",
    "            \n",
    "            # Reset the gradients for the forward phase\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            adapter_optimizer.zero_grad()\n",
    "\n",
    "            # Extract the data for the next batch\n",
    "            x, x_len, y, y_len, x_extra, vocab_ext = get_next_batch(cnn_data, p, vocab, i, batch_size, device=DEVICE)\n",
    "    \n",
    "            # Apply the embedding layer in the encoder\n",
    "            encoder_embedded = embedding(x)\n",
    "            # Create the init hidden state of the encoder\n",
    "            encoder_hidden=encoder.init_hidden(x.size(0), DEVICE)\n",
    "            # Forward pass in the encoder\n",
    "            encoder_outputs, encoder_hidden =encoder(encoder_embedded,encoder_hidden,x_len)\n",
    "            #Create the init input to the encoder\n",
    "            decoder_input = torch.tensor([vocab.SOS] * x.size(0), device=DEVICE)\n",
    "            # Adapt the encoder hidden to the encoder hidden size\n",
    "            decoder_hidden = enc_dec_adapter(encoder_hidden)\n",
    "            \n",
    "            decoder_states = []\n",
    "            enc_attn_weights = []\n",
    "            loss=0\n",
    "            # For every token in the target\n",
    "            for di in range(y.size(1)):\n",
    "                #Apply the embedding layer to the decoder input\n",
    "                decoder_embedded = embedding(decoder_input)\n",
    "                # If activation of encoder attention is on \n",
    "                if enc_attn_weights:\n",
    "                    coverage_vector = get_coverage_vector(enc_attn_weights)\n",
    "                else:\n",
    "                    coverage_vector = None\n",
    "                    \n",
    "                #Forward pass to the decoder\n",
    "                decoder_output, decoder_hidden, dec_enc_attn, dec_prob_ptr = decoder(decoder_embedded, decoder_hidden, encoder_outputs,\n",
    "                            torch.cat(decoder_states) if decoder_states else None, coverage_vector,\n",
    "                            encoder_word_idx=x_extra,log_prob=True,ext_vocab_size=len(vocab_ext))  \n",
    "                #Move the tensors to the device\n",
    "                decoder_output.to(DEVICE)\n",
    "                decoder_hidden.to(DEVICE)\n",
    "                dec_enc_attn.to(DEVICE)\n",
    "                dec_prob_ptr.to(DEVICE)\n",
    "                \n",
    "                #Save the decoder hidden state\n",
    "                decoder_states.append(decoder_hidden)\n",
    "                #Calculate the probability distribution of the decoder outputs\n",
    "                prob_distribution = torch.exp(decoder_output)# if log_prob else decoder_output\n",
    "                #Get the largest element \n",
    "                _, top_idx = decoder_output.data.topk(1)\n",
    "                # Set the current target word to our goal\n",
    "                gold_standard = y[:,di]\n",
    "                # Apply the loss function\n",
    "                nll_loss= criterion(decoder_output, gold_standard)    \n",
    "                loss+=nll_loss\n",
    "                \n",
    "                #Set the decoder input to the target word or token \n",
    "                decoder_input = y[:,di]\n",
    "                #Calculate the coverage loss\n",
    "                if (coverage_vector is not None and criterion): \n",
    "                    coverage_loss = torch.sum(torch.min(coverage_vector, dec_enc_attn)) / batch_size #* cover_loss            \n",
    "                    loss+=coverage_loss\n",
    "                    \n",
    "                #Store the attention weights\n",
    "                enc_attn_weights.append(dec_enc_attn.unsqueeze(0)) \n",
    "                \n",
    "            #Apply the backward to get the loss\n",
    "            loss.backward()\n",
    "            # Clipping the weights in the encoder, decoder and the adapter\n",
    "            clip_grad_norm_(encoder.parameters(), 1)\n",
    "            clip_grad_norm_(decoder.parameters(), 1)\n",
    "            clip_grad_norm_(enc_dec_adapter.parameters(), 1)\n",
    "            # Update the parameters\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            adapter_optimizer.step() \n",
    "            #Print the progress bar\n",
    "            if i%(p.print_every*batch_size)==0:\n",
    "                kbar.update(i, values=[(\"loss\", loss.data.item())])\n",
    "            # Get the next batch\n",
    "            i+=batch_size\n",
    "            \n",
    "        # Calculate the final loss on the training    \n",
    "        loss=loss.data.item()/x.size(0)\n",
    "        kbar.add(1, values=[(\"loss\", loss)])\n",
    "        \n",
    "        #Repeat the process on the validation dataset\n",
    "        kbar2 = pkbar.Kbar(target=len(val_data), width=8)\n",
    "        \n",
    "        # calculating validation loss\n",
    "        val_loss=0\n",
    "        i=0\n",
    "        while(i<len(val_data)):\n",
    "            # Reset the gradients for the forward phase\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            adapter_optimizer.zero_grad()\n",
    "            # Get the next batch of the validation data\n",
    "            x, x_len, y, y_len, x_extra, vocab_ext = get_next_batch(val_data, p, vocab, i, batch_size, device=DEVICE)\n",
    "            # Forward pass of the encoder\n",
    "            encoder_embedded = embedding(x)\n",
    "            encoder_hidden=encoder.init_hidden(x.size(0), device=DEVICE)\n",
    "            encoder_outputs, encoder_hidden =encoder(encoder_embedded,encoder_hidden,x_len)\n",
    "            decoder_input = torch.tensor([vocab.SOS] * x.size(0), device=DEVICE)\n",
    "            decoder_hidden = enc_dec_adapter(encoder_hidden)\n",
    "            \n",
    "            decoder_states = []\n",
    "            enc_attn_weights = []\n",
    "            # For every word in the output\n",
    "            for di in range(y.size(1)):\n",
    "                try:\n",
    "                    #Get the embedding vector of the input to the decoder\n",
    "                    decoder_embedded = embedding(decoder_input)\n",
    "                except:\n",
    "                    print('Dec input: ',decoder_input.shape,' x:', x.shape,' x_len:',x_len.shape, ' Vocab:', \n",
    "                          vocab.embeddings.shape,' Vocab Ext:', vocab_ext.embeddings.shape)\n",
    "                    decoder_embedded = embedding(decoder_input)\n",
    "                # Generate the coverage vectors if neccessary\n",
    "                if enc_attn_weights:\n",
    "                    coverage_vector = get_coverage_vector(enc_attn_weights)\n",
    "                else:\n",
    "                    coverage_vector = None\n",
    "                # Fordward pass ti the decoder\n",
    "                decoder_output, decoder_hidden, dec_enc_attn, dec_prob_ptr = decoder(decoder_embedded, decoder_hidden, encoder_outputs,\n",
    "                            torch.cat(decoder_states) if decoder_states else None, coverage_vector,\n",
    "                            encoder_word_idx=x_extra,log_prob=True,ext_vocab_size=len(vocab_ext))  \n",
    "                # Move the tensors to the device, gou or cpu\n",
    "                decoder_output.to(DEVICE)\n",
    "                decoder_hidden.to(DEVICE)\n",
    "                dec_enc_attn.to(DEVICE)\n",
    "                dec_prob_ptr.to(DEVICE)\n",
    "                # Stores the hidden states of the decoder\n",
    "                decoder_states.append(decoder_hidden)      \n",
    "                prob_distribution = torch.exp(decoder_output)# if log_prob else decoder_output\n",
    "                # Get the output token with the highest probability\n",
    "                _, top_idx = decoder_output.data.topk(1)\n",
    "                gold_standard = y[:,di]\n",
    "                # Apply the loss function\n",
    "                nll_loss= criterion(decoder_output, gold_standard)    \n",
    "                val_loss+=nll_loss.data.item()\n",
    "                \n",
    "                # Set the decoder input to the last output from the decoder\n",
    "                decoder_input = top_idx.view(-1) #y[:,di]\n",
    "                # update the coverage vector\n",
    "                if (coverage_vector is not None and criterion): #and cover_loss > 0:\n",
    "                    coverage_loss = torch.sum(torch.min(coverage_vector, dec_enc_attn)) / batch_size #* cover_loss            \n",
    "                    val_loss+=coverage_loss.data.item()\n",
    "                # Collect the attention weights in the step    \n",
    "                enc_attn_weights.append(dec_enc_attn.unsqueeze(0))  \n",
    "            # Print the progress\n",
    "            if i%(p.print_every*batch_size)==0:\n",
    "                kbar2.update(i, values=[(\"Val loss\", val_loss)])\n",
    "\n",
    "            i+=batch_size\n",
    "            \n",
    "        #Calculate the validation loss\n",
    "        avg_val_loss=val_loss/len(val_data)        \n",
    "        #print('training loss:{}'.format(loss),'validation loss:{}'.format(avg_val_loss))\n",
    "        kbar2.add(1, values=[(\"Train loss\", loss), (\"Val loss\", val_loss), (\"Avg Val loss\", avg_val_loss)])\n",
    "        \n",
    "        # Save the mnodel and results to disk\n",
    "        if(len(val_losses)>0 and avg_val_loss<min(val_losses)):\n",
    "            torch.save(encoder.state_dict(), p.encoder_weights_path)\n",
    "            torch.save(decoder.state_dict(), p.decoder_weights_path)\n",
    "            torch.save(enc_dec_adapter.state_dict(), p.encoder_decoder_adapter_weights_path)\n",
    "            # torch.save(embedding.state_dict(), '/home/svu/e0401988/NLP/summarization/embedding_sum.pt')\n",
    "        val_losses.append(avg_val_loss) \n",
    "    \n",
    "    with open(p.losses_path,'wb') as f:\n",
    "        pickle.dump(val_losses,f) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.410217Z",
     "iopub.status.busy": "2023-08-21T10:02:39.409686Z",
     "iopub.status.idle": "2023-08-21T10:02:39.446464Z",
     "shell.execute_reply": "2023-08-21T10:02:39.445450Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.410187Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(sent,vocab,p,batch_size=1):\n",
    "    ''' Function to predict the summary of the source text sentence\n",
    "        Input:\n",
    "        - sent: string, text to summarize\n",
    "        - vocab: a class Vocab object, vocabulary of the texts\n",
    "        - p: a class Parameters object, model parameters\n",
    "        - batch_size: integer, batch size of the data to predict\n",
    "    '''\n",
    "    eps=p.eps\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Create a tensor with the embedding vectors\n",
    "    embedding_weights = torch.from_numpy(vocab.embeddings).to(DEVICE)\n",
    "    # Create the layer to transform inputs between encoder and decoder\n",
    "    enc_dec_adapter = nn.Linear(p.hidden_size * 2, p.dec_hidden_size).to(DEVICE)\n",
    "    # Create the embedding layer using the embedding vectors\n",
    "    embedding = nn.Embedding(len(vocab), p.embed_size, padding_idx=vocab.PAD,_weight=embedding_weights).to(DEVICE)\n",
    "    # Create the encoder and the decoder\n",
    "    encoder = EncoderRNN(p.embed_size, p.hidden_size, p.enc_bidi,rnn_drop=p.enc_rnn_dropout).to(DEVICE)\n",
    "    decoder = DecoderRNN(len(vocab), p.embed_size, p.dec_hidden_size,\n",
    "                                  enc_attn=p.enc_attn, dec_attn=p.dec_attn,\n",
    "                                  pointer=p.pointer,\n",
    "                                  in_drop=p.dec_in_dropout, rnn_drop=p.dec_rnn_dropout,\n",
    "                                  out_drop=p.dec_out_dropout, enc_hidden_size=p.hidden_size * 2,\n",
    "                                  device=DEVICE).to(DEVICE) \n",
    "    # Tokenize the input text \n",
    "    sent_vec=[vocab[word] for word in sent.split()]\n",
    "    vocab_ext=deepcopy(vocab)\n",
    "    # Extend the vocabulary\n",
    "    for word in sent.split():\n",
    "      vocab_ext.add_words(word)\n",
    "    # Tokenize the text with the extended  vocabulary\n",
    "    sent_vec_extra=[vocab_ext[word] for word in sent.split()] \n",
    "    # Pad the text if neccessary\n",
    "    if(len(sent_vec_extra)<p.max_src_len):\n",
    "        pad_dim = (0, p.max_src_len-len(sent_vec_extra))\n",
    "        #sent_vec_extra=F.pad(sent_vec_extra, pad_dim , 'constant')\n",
    "        sent_vec_extra_tensor=F.pad(torch.tensor(sent_vec_extra), pad_dim , 'constant')\n",
    "    else:\n",
    "        sent_vec_extra_tensor=torch.tensor(sent_vec_extra)\n",
    "        \n",
    "    # Pad the text if neccessary\n",
    "    if(len(sent_vec)<p.max_src_len):\n",
    "        pad_dim = (0, p.max_src_len-len(sent_vec))\n",
    "        #sent_vec=F.pad(sent_vec, pad_dim, 'constant')\n",
    "        sent_vec_tensor=F.pad(torch.tensor(sent_vec), pad_dim, 'constant')\n",
    "    else:\n",
    "        sent_vec_tensor=torch.tensor(sent_vec)\n",
    "        \n",
    "    # Load the encoder model from file\n",
    "    if(os.path.exists(p.encoder_weights_path)):\n",
    "        encoder.load_state_dict(torch.load(p.encoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    # Load the decoder model from file\n",
    "    if(os.path.exists(p.decoder_weights_path)):\n",
    "        decoder.load_state_dict(torch.load(p.decoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    # Load the encoder -decoder adapter component from file\n",
    "    if(os.path.exists(p.encoder_decoder_adapter_weights_path)):    \n",
    "        enc_dec_adapter.load_state_dict(torch.load(p.encoder_decoder_adapter_weights_path,map_location=torch.device(DEVICE)))\n",
    "\n",
    "    x=sent_vec_tensor.view(1,-1).to(DEVICE)\n",
    "    x_extra=sent_vec_extra_tensor.view(1,-1).to(DEVICE)\n",
    "    # Apply the embedding layer\n",
    "    encoder_embedded = embedding(x)\n",
    "    # Initiaize the hidden state of the encoder\n",
    "    encoder_hidden=encoder.init_hidden(x.size(0), DEVICE)\n",
    "    # Fordward pass to the encoder\n",
    "    encoder_outputs, encoder_hidden =encoder(encoder_embedded,encoder_hidden,\n",
    "                                             torch.tensor(p.max_src_len).view(1).to(DEVICE))\n",
    "    # Initialize the decoder input to SOS tokens\n",
    "    decoder_input = torch.tensor([vocab.SOS] * batch_size, device=DEVICE)\n",
    "    decoder_hidden = enc_dec_adapter(encoder_hidden)\n",
    "    \n",
    "    #Initialize the hidden states and weights of some variables\n",
    "    decoder_states = []\n",
    "    enc_attn_weights = []\n",
    "    output=[]\n",
    "    # For every word in the output sequence \n",
    "    for di in range(p.max_tgt_len):\n",
    "        # Apply the embedding layer of the decoder\n",
    "        decoder_embedded = embedding(decoder_input)\n",
    "        # Get the coverage vector\n",
    "        if enc_attn_weights:\n",
    "            coverage_vector = get_coverage_vector(enc_attn_weights)\n",
    "        else:\n",
    "            coverage_vector = None\n",
    "        # fordward pass to the decoder\n",
    "        decoder_output, decoder_hidden, dec_enc_attn, dec_prob_ptr = decoder(decoder_embedded, decoder_hidden, encoder_outputs,\n",
    "                    torch.cat(decoder_states).to(DEVICE) if decoder_states else None, coverage_vector,\n",
    "                    encoder_word_idx=x_extra,log_prob=True,ext_vocab_size=len(vocab_ext))  \n",
    "        # Move the tensor to the device\n",
    "        decoder_output.to(DEVICE)\n",
    "        decoder_hidden.to(DEVICE)\n",
    "        dec_enc_attn.to(DEVICE)\n",
    "        dec_prob_ptr.to(DEVICE)\n",
    "        # Store the hidden state of the decoder\n",
    "        decoder_states.append(decoder_hidden)\n",
    "        # Generate the probability distribution\n",
    "        prob_distribution = torch.exp(decoder_output)# if log_prob else decoder_output\n",
    "        # Get the element in the decoder output with the highest probability (the best output)\n",
    "        _, top_idx = decoder_output.data.topk(1)\n",
    "        # Store the output (word) to the output text\n",
    "        output.append(top_idx.squeeze().data.item())\n",
    "        # Store the encoder attention weights\n",
    "        enc_attn_weights.append(dec_enc_attn.unsqueeze(0))\n",
    "        # Set the decoder input in the next iter\n",
    "        decoder_input = top_idx.view(-1)\n",
    "    # Transform the outputs (words) to a list of text or words\n",
    "    output=[vocab_ext[idx] for idx in output]    \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.448216Z",
     "iopub.status.busy": "2023-08-21T10:02:39.447765Z",
     "iopub.status.idle": "2023-08-21T10:02:39.472492Z",
     "shell.execute_reply": "2023-08-21T10:02:39.471632Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.448168Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(sent,vocab,embedding, encoder, enc_dec_adapter, decoder, device, p,batch_size=1):\n",
    "    ''' Function to predict the summary of the source text sentence\n",
    "        Input:\n",
    "        - sent: string, text to summarize\n",
    "        - vocab: a class Vocab object, vocabulary of the texts\n",
    "        - p: a class Parameters object, model parameters\n",
    "        - batch_size: integer, batch size of the data to predict\n",
    "    '''\n",
    "    eps=p.eps\n",
    "    # Tokenize the input text \n",
    "    sent_vec=[vocab[word] for word in sent.split()]\n",
    "    vocab_ext=deepcopy(vocab)\n",
    "    # Extend the vocabulary\n",
    "    for word in sent.split():\n",
    "      vocab_ext.add_words(word)\n",
    "    # Tokenize the text with the extended  vocabulary\n",
    "    sent_vec_extra=[vocab_ext[word] for word in sent.split()] \n",
    "    # Pad the text if neccessary\n",
    "    if(len(sent_vec_extra)<p.max_src_len):\n",
    "        pad_dim = (0, p.max_src_len-len(sent_vec_extra))\n",
    "        #sent_vec_extra=F.pad(sent_vec_extra, pad_dim , 'constant')\n",
    "        sent_vec_extra_tensor=F.pad(torch.tensor(sent_vec_extra), pad_dim , 'constant')\n",
    "    else:\n",
    "        sent_vec_extra_tensor=torch.tensor(sent_vec_extra)\n",
    "        \n",
    "    # Pad the text if neccessary\n",
    "    if(len(sent_vec)<p.max_src_len):\n",
    "        pad_dim = (0, p.max_src_len-len(sent_vec))\n",
    "        #sent_vec=F.pad(sent_vec, pad_dim, 'constant')\n",
    "        sent_vec_tensor=F.pad(torch.tensor(sent_vec), pad_dim, 'constant')\n",
    "    else:\n",
    "        sent_vec_tensor=torch.tensor(sent_vec)\n",
    "        \n",
    "    x=sent_vec_tensor.view(1,-1).to(device)\n",
    "    x_extra=sent_vec_extra_tensor.view(1,-1).to(device)\n",
    "    # Apply the embedding layer\n",
    "    encoder_embedded = embedding(x)\n",
    "    # Initiaize the hidden state of the encoder\n",
    "    encoder_hidden=encoder.init_hidden(x.size(0), device)\n",
    "    # Fordward pass to the encoder\n",
    "    encoder_outputs, encoder_hidden =encoder(encoder_embedded,encoder_hidden,\n",
    "                                             torch.tensor(p.max_src_len).view(1).to(device))\n",
    "    # Initialize the decoder input to SOS tokens\n",
    "    decoder_input = torch.tensor([vocab.SOS] * batch_size, device=device)\n",
    "    decoder_hidden = enc_dec_adapter(encoder_hidden)\n",
    "    \n",
    "    #Initialize the hidden states and weights of some variables\n",
    "    decoder_states = []\n",
    "    enc_attn_weights = []\n",
    "    output=[]\n",
    "    # For every word in the output sequence \n",
    "    for di in range(p.max_tgt_len):\n",
    "        # Apply the embedding layer of the decoder\n",
    "        decoder_embedded = embedding(decoder_input)\n",
    "        # Get the coverage vector\n",
    "        if enc_attn_weights:\n",
    "            coverage_vector = get_coverage_vector(enc_attn_weights)\n",
    "        else:\n",
    "            coverage_vector = None\n",
    "            \n",
    "        # fordward pass to the decoder\n",
    "        decoder_output, decoder_hidden, dec_enc_attn, dec_prob_ptr = decoder(decoder_embedded, decoder_hidden, encoder_outputs,\n",
    "                    torch.cat(decoder_states).to(device) if decoder_states else None, coverage_vector,\n",
    "                    encoder_word_idx=x_extra,log_prob=True,ext_vocab_size=len(vocab_ext))  \n",
    "        # Move the tensor to the device\n",
    "        decoder_output.to(device)\n",
    "        decoder_hidden.to(device)\n",
    "        dec_enc_attn.to(device)\n",
    "        dec_prob_ptr.to(device)\n",
    "        # Store the hidden state of the decoder\n",
    "        decoder_states.append(decoder_hidden)\n",
    "        # Generate the probability distribution\n",
    "        prob_distribution = torch.exp(decoder_output)# if log_prob else decoder_output\n",
    "        # Get the element in the decoder output with the highest probability (the best output)\n",
    "        _, top_idx = decoder_output.data.topk(1)\n",
    "        # Store the output (word) to the output text\n",
    "        output.append(top_idx.squeeze().data.item())\n",
    "        # Store the encoder attention weights\n",
    "        enc_attn_weights.append(dec_enc_attn.unsqueeze(0))\n",
    "        # Set the decoder input in the next iter\n",
    "        decoder_input = top_idx.view(-1)\n",
    "        \n",
    "    # Transform the outputs (words) to a list of text or words\n",
    "    output=[vocab_ext[idx] for idx in output]    \n",
    "    return output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to evaluate the model and calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.474613Z",
     "iopub.status.busy": "2023-08-21T10:02:39.474105Z",
     "iopub.status.idle": "2023-08-21T10:02:39.492842Z",
     "shell.execute_reply": "2023-08-21T10:02:39.491950Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.474575Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_metrics(preds, targets, avg=True):\n",
    "    ''' Evaluate the ROUGE metrics ROUGE-2 and ROUGE-L for every pair predicted summary - target summary\n",
    "    \n",
    "        Input:\n",
    "           - preds: list of strings, predicted summaries\n",
    "           - targets: list of string, target summaries\n",
    "        Output:\n",
    "            - rouge2_f_metric: list of float, the Rouge-2 fscore for every predicted summary\n",
    "            - rougel_f_metric: list of float, the Rouge-L fscore for every predicted summary\n",
    "    '''\n",
    "    #Lets calculate the rouge metrics for every document\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(preds, targets, avg)\n",
    "    # Create the output variables\n",
    "    if avg:\n",
    "        rouge2_f_metric = scores['rouge-2']['f']\n",
    "        rouge2_p_metric = scores['rouge-2']['p']\n",
    "        rouge2_r_metric = scores['rouge-2']['r']\n",
    "        rougel_f_metric = scores['rouge-l']['f']\n",
    "        rougel_p_metric = scores['rouge-l']['p']\n",
    "        rougel_r_metric = scores['rouge-l']['r']\n",
    "    else:\n",
    "        rouge2_f_metric = [score['rouge-2']['f'] for score in scores]\n",
    "        rouge2_p_metric = [score['rouge-2']['p'] for score in scores]\n",
    "        rouge2_r_metric = [score['rouge-2']['r'] for score in scores]\n",
    "        rougel_f_metric = [score['rouge-l']['f'] for score in scores]\n",
    "        rougel_p_metric = [score['rouge-l']['p'] for score in scores]\n",
    "        rougel_r_metric = [score['rouge-l']['r'] for score in scores]\n",
    "    \n",
    "    return rouge2_f_metric, rouge2_p_metric, rouge2_r_metric, rougel_f_metric, rougel_p_metric, rougel_r_metric\n",
    "\n",
    "def save_to_df(text, labeled_summaries, predicted_summaries, r2_f, r2_p, r2_r, rl_f, rl_p, rl_r):\n",
    "    ''' Stores the metric results into a pandas dataframe'''\n",
    "    results = pd.DataFrame(columns=['text', 'summary','pred_summary','rouge2-f','rouge2-p','rouge2-r','rougel-f', 'rougel-p', 'rougel-r'])\n",
    "    results['text'] = text\n",
    "    results['summary'] = labeled_summaries\n",
    "    results['pred_summary'] = predicted_summaries\n",
    "    results['rouge2-f'] = r2_f\n",
    "    results['rouge2-p'] = r2_p\n",
    "    results['rouge2-r'] = r2_r\n",
    "    results['rougel-f'] = rl_f\n",
    "    results['rougel-p'] = rl_p\n",
    "    results['rougel-r'] = rl_r\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.495216Z",
     "iopub.status.busy": "2023-08-21T10:02:39.494817Z",
     "iopub.status.idle": "2023-08-21T10:02:39.515373Z",
     "shell.execute_reply": "2023-08-21T10:02:39.514580Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.495179Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(x_test, vocab, params, print_every=20):\n",
    "    ''' Generate the predicted summaries of the source texts on x_test\n",
    "        Input:\n",
    "        - x_test: list of strings, the source texts\n",
    "        - vocab: a Vocab Class object, vocabulary of the texts\n",
    "        - params: a Parameters object, parameter of the model\n",
    "        - print_every: integer, print progress every print_every iterations\n",
    "    '''\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Create a tensor with the embedding vectors\n",
    "    embedding_weights = torch.from_numpy(vocab.embeddings).to(DEVICE)\n",
    "    # Create the layer to transform inputs between encoder and decoder\n",
    "    enc_dec_adapter = nn.Linear(params.hidden_size * 2, params.dec_hidden_size).to(DEVICE)\n",
    "    # Create the embedding layer using the embedding vectors\n",
    "    embedding = nn.Embedding(len(vocab), params.embed_size, padding_idx=vocab.PAD,_weight=embedding_weights).to(DEVICE)\n",
    "    # Create the encoder and the decoder\n",
    "    encoder = EncoderRNN(params.embed_size,params.hidden_size, params.enc_bidi,rnn_drop=params.enc_rnn_dropout).to(DEVICE)\n",
    "    decoder = DecoderRNN(len(vocab), params.embed_size, params.dec_hidden_size,\n",
    "                                  enc_attn=params.enc_attn, dec_attn=params.dec_attn,\n",
    "                                  pointer=params.pointer,\n",
    "                                  in_drop=params.dec_in_dropout, rnn_drop=params.dec_rnn_dropout,\n",
    "                                  out_drop=params.dec_out_dropout, enc_hidden_size=params.hidden_size * 2,\n",
    "                                  device=DEVICE).to(DEVICE) \n",
    "\n",
    "    # Load the encoder model from file\n",
    "    if(os.path.exists(params.encoder_weights_path)):\n",
    "        encoder.load_state_dict(torch.load(params.encoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    # Load the decoder model from file\n",
    "    if(os.path.exists(params.decoder_weights_path)):\n",
    "        decoder.load_state_dict(torch.load(params.decoder_weights_path,map_location=torch.device(DEVICE)))\n",
    "    # Load the encoder -decoder adapter component from file\n",
    "    if(os.path.exists(params.encoder_decoder_adapter_weights_path)):    \n",
    "        enc_dec_adapter.load_state_dict(torch.load(params.encoder_decoder_adapter_weights_path,map_location=torch.device(DEVICE)))\n",
    "\n",
    "        \n",
    "    predicted_summaries = []\n",
    "    # Set a progress bar\n",
    "    kbar = pkbar.Kbar(target=len(x_test), width=8)\n",
    "    # For every text in the validation dataset\n",
    "    for i,doc in enumerate(x_test):\n",
    "        # Predict the summary for the document\n",
    "        pred_summ = prediction(doc,vocab,embedding,encoder,enc_dec_adapter,decoder,DEVICE,params,batch_size=1)\n",
    "        #pred_summ = predict(doc,vocab,params,batch_size=1)\n",
    "        predicted_summaries.append(' '.join(pred_summ))\n",
    "        #Show the progress\n",
    "        if i%print_every==0:\n",
    "            kbar.update(i)\n",
    "            \n",
    "    # Set the labeled summaries as the y_test variable, column summary of our dataset\n",
    "    return predicted_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.517191Z",
     "iopub.status.busy": "2023-08-21T10:02:39.516649Z",
     "iopub.status.idle": "2023-08-21T10:02:39.526018Z",
     "shell.execute_reply": "2023-08-21T10:02:39.525400Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.517143Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_predictions(x_test, vocab, params, print_every=20):\n",
    "    ''' Generate the predicted summaries of the source texts on x_test\n",
    "        Input:\n",
    "        - x_test: list of strings, the source texts\n",
    "        - vocab: a Vocab Class object, vocabulary of the texts\n",
    "        - params: a Parameters object, parameter of the model\n",
    "        - print_every: integer, print progress every print_every iterations\n",
    "    '''\n",
    "\n",
    "    predicted_summaries = []\n",
    "    # Set a progress bar\n",
    "    kbar = pkbar.Kbar(target=len(x_test), width=8)\n",
    "    # For every text in the validation dataset\n",
    "    for i,doc in enumerate(x_test):\n",
    "        # Predict the summary for the document\n",
    "        pred_summ = predict(doc,vocab,params,batch_size=1)\n",
    "        predicted_summaries.append(' '.join(pred_summ))\n",
    "        #Show the progress\n",
    "        if i%print_every==0:\n",
    "            kbar.update(i)\n",
    "            \n",
    "    # Set the labeled summaries as the y_test variable, column summary of our dataset\n",
    "    return predicted_summaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code\n",
    "\n",
    "Now that we have defined the group of functions we need to work with our datasets, we can invoke them an train and evaluate out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.527823Z",
     "iopub.status.busy": "2023-08-21T10:02:39.527241Z",
     "iopub.status.idle": "2023-08-21T10:02:39.536133Z",
     "shell.execute_reply": "2023-08-21T10:02:39.535461Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.527779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an object with the model and training parameters\n",
    "params = Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:39.537795Z",
     "iopub.status.busy": "2023-08-21T10:02:39.537278Z",
     "iopub.status.idle": "2023-08-21T10:02:41.030653Z",
     "shell.execute_reply": "2023-08-21T10:02:41.029145Z",
     "shell.execute_reply.started": "2023-08-21T10:02:39.537757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset /kaggle/input/cleaned-news-summary/cl_train_news_summary_more.csv... 64000 pairs.\n",
      "Reading dataset /kaggle/input/cleaned-news-summary/cl_train_news_summary_more.csv... 3200 pairs.\n",
      "61 54 14 13\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset using the simple tokenizer\n",
    "dataset = Dataset(params.data_path, simple_tokenizer, params.max_src_len, params.max_tgt_len, max_rows=64000,\n",
    "                        truncate_src=True, truncate_tgt=True)\n",
    "# Load the validation dataset using the simple tokenizer\n",
    "valid_dataset = Dataset(params.val_data_path, simple_tokenizer, params.max_src_len, params.max_tgt_len, max_rows= 3200,\n",
    "                        truncate_src=True, truncate_tgt=True)\n",
    "#Show the length to check the loadings\n",
    "print(dataset.src_len, valid_dataset.src_len,dataset.tgt_len, valid_dataset.tgt_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build our vocabulary, load the embedding vectors and transform them to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:41.032571Z",
     "iopub.status.busy": "2023-08-21T10:02:41.032179Z",
     "iopub.status.idle": "2023-08-21T10:02:45.681229Z",
     "shell.execute_reply": "2023-08-21T10:02:45.680137Z",
     "shell.execute_reply.started": "2023-08-21T10:02:41.032529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29022 pre-trained embeddings loaded.\n"
     ]
    }
   ],
   "source": [
    "# convert the embeddings to a tensor\n",
    "vocab = dataset.build_vocab(params.vocab_min_frequency, embed_file=params.embed_file)\n",
    "vocab.save_to_file('vocab_train.pkl')\n",
    "# convert the embeddings to a tensor\n",
    "embedding_weights = torch.from_numpy(vocab.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:45.683323Z",
     "iopub.status.busy": "2023-08-21T10:02:45.682702Z",
     "iopub.status.idle": "2023-08-21T10:02:45.687506Z",
     "shell.execute_reply": "2023-08-21T10:02:45.686516Z",
     "shell.execute_reply.started": "2023-08-21T10:02:45.683279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the vocab from file\n",
    "#vocab= load_vocab('/kaggle/input/pointer-trained-model/vocab_train.pkl')\n",
    "#print(vocab.embeddings.shape, len(vocab.index2word))\n",
    "#embedding_weights = torch.from_numpy(vocab.embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to train the model using the parameters in the params variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T10:02:45.689693Z",
     "iopub.status.busy": "2023-08-21T10:02:45.689117Z",
     "iopub.status.idle": "2023-08-21T13:43:17.806531Z",
     "shell.execute_reply": "2023-08-21T13:43:17.805474Z",
     "shell.execute_reply.started": "2023-08-21T10:02:45.689654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/10\n",
      "1601/3200 [===>....] - ETA: 48s - Val loss: 5754.1252 - Train loss: 2.8664 - Avg Val loss: 3.5619\n",
      "Epoch: 2/10\n",
      "1601/3200 [===>....] - ETA: 50s - Val loss: 5662.0877 - Train loss: 2.4028 - Avg Val loss: 3.5241\n",
      "Epoch: 3/10\n",
      "1601/3200 [===>....] - ETA: 47s - Val loss: 5716.1441 - Train loss: 2.2876 - Avg Val loss: 3.5712\n",
      "Epoch: 4/10\n",
      "1601/3200 [===>....] - ETA: 47s - Val loss: 5739.8222 - Train loss: 2.0732 - Avg Val loss: 3.5640\n",
      "Epoch: 5/10\n",
      "1601/3200 [===>....] - ETA: 47s - Val loss: 5759.5559 - Train loss: 2.3559 - Avg Val loss: 3.5884\n",
      "Epoch: 6/10\n",
      "1601/3200 [===>....] - ETA: 47s - Val loss: 5772.2495 - Train loss: 1.9816 - Avg Val loss: 3.6102\n",
      "Epoch: 7/10\n",
      "1601/3200 [===>....] - ETA: 47s - Val loss: 5656.7755 - Train loss: 1.8777 - Avg Val loss: 3.5610\n",
      "Epoch: 8/10\n",
      "1601/3200 [===>....] - ETA: 48s - Val loss: 5775.5963 - Train loss: 1.6637 - Avg Val loss: 3.6474\n",
      "Epoch: 9/10\n",
      "1601/3200 [===>....] - ETA: 49s - Val loss: 5742.7656 - Train loss: 1.6786 - Avg Val loss: 3.6433\n",
      "Epoch: 10/10\n",
      "1601/3200 [===>....] - ETA: 49s - Val loss: 5843.2857 - Train loss: 1.5512 - Avg Val loss: 3.6703"
     ]
    }
   ],
   "source": [
    "train(dataset,valid_dataset,vocab, params, embedding_weights,learning_rate=0.001,num_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test dataset to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T13:43:17.808622Z",
     "iopub.status.busy": "2023-08-21T13:43:17.808239Z",
     "iopub.status.idle": "2023-08-21T13:55:52.907773Z",
     "shell.execute_reply": "2023-08-21T13:55:52.906788Z",
     "shell.execute_reply.started": "2023-08-21T13:43:17.808579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset /kaggle/input/cleaned-news-summary/cl_valid_news_summary_more.csv... 3200 pairs.\n",
      "Length Test Dataset: 3200\n",
      "3100/3200 [======>.] - ETA: 23s\n",
      "Mean Rouge-2 FScore:  0.12540976831274064 Mean Rouge-L FScore:  0.3274297272396094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>pred_summary</th>\n",
       "      <th>rouge2-f</th>\n",
       "      <th>rouge2-p</th>\n",
       "      <th>rouge2-r</th>\n",
       "      <th>rougel-f</th>\n",
       "      <th>rougel-p</th>\n",
       "      <th>rougel-r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hrd ministry formed threemember special invest...</td>\n",
       "      <td>govt forms sit ryan murder case cbse seeks saf...</td>\n",
       "      <td>hrd formed threemember probe murder sevenyearo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>letter written jail sheena bora murder accused...</td>\n",
       "      <td>indrani asks furniture jewellery divorce report</td>\n",
       "      <td>jail sheena bora murder accused indrani keys s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enforcement directorate ed friday conducted se...</td>\n",
       "      <td>ed raids 35 premises nirav modi â assets seized</td>\n",
       "      <td>ed friday searches covering new locations frau...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>japan acknowledged first time worker died radi...</td>\n",
       "      <td>japan admits 1st death 2011 fukushima nuclear ...</td>\n",
       "      <td>japan acknowledged first time worker died radi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entire village germany auctioned weekend bids ...</td>\n",
       "      <td>entire village germany auctioned</td>\n",
       "      <td>entire village village germany auctioned weeke...</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>manchester united luckiest team liverpool unlu...</td>\n",
       "      <td>man utd luckiest pl team liverpool unluckiest ...</td>\n",
       "      <td>manchester united team premier league last sea...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>csks suresh raina overtook rcb captain virat k...</td>\n",
       "      <td>raina overtakes kohli become ipls top runscorer</td>\n",
       "      <td>raina overtakes rcb virat become alltime leadi...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>residents 20storey housing complex kandivli mu...</td>\n",
       "      <td>mumbai housing society saves â lakh month elec...</td>\n",
       "      <td>residents &lt;UNK&gt; housing complex mumbai saving ...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>first time nine years operations southern hemi...</td>\n",
       "      <td>nasa launches two antarctic flights two contin...</td>\n",
       "      <td>first time nine years operations southern hemi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>us defence secretary james mattis criticised p...</td>\n",
       "      <td>pentagon slammed wasting â cr afghan army unif...</td>\n",
       "      <td>us defence secy criticised spending â crore ta...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hundreds muslims prayed outside white house fr...</td>\n",
       "      <td>muslims pray outside white house protest jerus...</td>\n",
       "      <td>hundreds muslims prayed outside trump piece so...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>swimming water sports across beaches goa close...</td>\n",
       "      <td>swimming water sports goa beaches closed monsoon</td>\n",
       "      <td>swimming water sports across beaches goa close...</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>actress katrina kaif said disagrees word item ...</td>\n",
       "      <td>disagree term item song katrina kaif</td>\n",
       "      <td>disagrees word item song girls katrina kaif sa...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>anushka sharma denying rumours pregnancy said ...</td>\n",
       "      <td>hide marriage pregnancy anushka pregnancy rumours</td>\n",
       "      <td>spreading rumours something people anyway anus...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>former uttar pradesh cm akhilesh yadav accused...</td>\n",
       "      <td>remove hand cycle handle akhilesh warns cong</td>\n",
       "      <td>congress stopping cycle pollbound chhattisgarh...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gujarat lions defeated royal challengers banga...</td>\n",
       "      <td>finch scores fastest fifty gl 7wicket win rcb</td>\n",
       "      <td>gujarat lions defeated royal challengers 7 wic...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>messages cyclone mumbai went viral social medi...</td>\n",
       "      <td>mumbai cyclone alert rumour clarifies civic body</td>\n",
       "      <td>cyclone mumbai went viral social media brihanm...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>australian womens team spinner amandajade well...</td>\n",
       "      <td>ball century like delivery bowled womens ashes</td>\n",
       "      <td>australian womens team dismissal womens ashes ...</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>singer sonu nigam monday took twitter tweet mu...</td>\n",
       "      <td>muslim woken azaan sonu nigam</td>\n",
       "      <td>sonu nigam shares tweet muslim still woken mor...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sevenyearold girl allegedly raped man neighbou...</td>\n",
       "      <td>7yearold girl raped neighbours terrace delhi</td>\n",
       "      <td>sevenyearold girl raped man neighbours terrace...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nearly 1 million cash stolen former zimbabwe p...</td>\n",
       "      <td>1million stolen exzimbabwe president mugabes h...</td>\n",
       "      <td>1 million cash stolen former zimbabwe presiden...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>indian pacer mohammed shami trolled social med...</td>\n",
       "      <td>mohammed shami trolled daughters bday celebrat...</td>\n",
       "      <td>pacer mohammed shami wife daughters second bir...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>state funeral accorded veteran bollywood actre...</td>\n",
       "      <td>state funeral sridevi ordered maha cm rti reply</td>\n",
       "      <td>state funeral accorded veteran bollywood actre...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>south korean electronics conglomerate samsung ...</td>\n",
       "      <td>samsung plans invest 22 billion ai 5g technology</td>\n",
       "      <td>samsung plans 22 billion develop technologies ...</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bill seeks increase allotment green cards 45 c...</td>\n",
       "      <td>bill increase green card allotments 45 propose...</td>\n",
       "      <td>indianamerican technology professionals increa...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>per reports actress sonam kapoor auction desig...</td>\n",
       "      <td>sonam auction clothes bags charity report</td>\n",
       "      <td>sonam auction designer outfits bags raise hung...</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rohit sharma included team indias final xii fi...</td>\n",
       "      <td>rohit included indias 12man squad first test v...</td>\n",
       "      <td>rohit sharma included team indias final test a...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>minister state railways rajen gohain wednesday...</td>\n",
       "      <td>mumbai locals caused losses worth â crore 3 years</td>\n",
       "      <td>railways suffered losses worth â crore operati...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>many 11 people killed vehicle carrying machel ...</td>\n",
       "      <td>11 killed vehicle carrying pilgrims rolls jk</td>\n",
       "      <td>11 killed vehicle carrying chenab river jammu ...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>second advisory vandalism statues ministry hom...</td>\n",
       "      <td>ensure prompt action statue vandalism case mha...</td>\n",
       "      <td>second advisory vandalism statues ministry hom...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>juventus forward cristiano ronaldo went greece...</td>\n",
       "      <td>ronaldo leaves â tip staff greek luxury resort</td>\n",
       "      <td>ronaldo went greece holiday family friends por...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>estonia opening worlds firstever data embassy ...</td>\n",
       "      <td>estonia open worlds 1st data embassy luxembourg</td>\n",
       "      <td>estonia opening worlds firstever data embassy ...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cristiano ronaldo scored hattrick real madrid ...</td>\n",
       "      <td>ronaldo scores hattrick real madrid go 3rd la ...</td>\n",
       "      <td>ronaldo scores hattrick real madrid moved thir...</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>uber wednesday said partnered nasa develop sof...</td>\n",
       "      <td>uber partners nasa build flying taxi air contr...</td>\n",
       "      <td>uber partnered software manage air routes uber...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>television actress saumya tandon reportedly pl...</td>\n",
       "      <td>saumya tandon quit bhabi ji ghar par hai seria...</td>\n",
       "      <td>saumya tandon reportedly quit television seria...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>jds supremo deve gowda asked congress treat re...</td>\n",
       "      <td>congress treat us well forming alliance gowda</td>\n",
       "      <td>jds supremo deve treat regional parties treat ...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mumbai police official thursday said employee ...</td>\n",
       "      <td>canadian woman allegedly molested 5star hotel ...</td>\n",
       "      <td>mumbai police official employee molesting 35ye...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>microsoft ceo satya nadella wednesday said tec...</td>\n",
       "      <td>us prevent future like 1984â microsoft ceo</td>\n",
       "      <td>technology sector ensure future imagined georg...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>talking competition bollywood katrina kaif sai...</td>\n",
       "      <td>would insane compete 2021 yr olds katrina kaif</td>\n",
       "      <td>would insane illogical compete 2021 years kaif...</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>branch china construction bank offered chinese...</td>\n",
       "      <td>chinese bank offers clients dinner trump 150000</td>\n",
       "      <td>branch china construction bank offers dinner u...</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   hrd ministry formed threemember special invest...   \n",
       "1   letter written jail sheena bora murder accused...   \n",
       "2   enforcement directorate ed friday conducted se...   \n",
       "3   japan acknowledged first time worker died radi...   \n",
       "4   entire village germany auctioned weekend bids ...   \n",
       "5   manchester united luckiest team liverpool unlu...   \n",
       "6   csks suresh raina overtook rcb captain virat k...   \n",
       "7   residents 20storey housing complex kandivli mu...   \n",
       "8   first time nine years operations southern hemi...   \n",
       "9   us defence secretary james mattis criticised p...   \n",
       "10  hundreds muslims prayed outside white house fr...   \n",
       "11  swimming water sports across beaches goa close...   \n",
       "12  actress katrina kaif said disagrees word item ...   \n",
       "13  anushka sharma denying rumours pregnancy said ...   \n",
       "14  former uttar pradesh cm akhilesh yadav accused...   \n",
       "15  gujarat lions defeated royal challengers banga...   \n",
       "16  messages cyclone mumbai went viral social medi...   \n",
       "17  australian womens team spinner amandajade well...   \n",
       "18  singer sonu nigam monday took twitter tweet mu...   \n",
       "19  sevenyearold girl allegedly raped man neighbou...   \n",
       "20  nearly 1 million cash stolen former zimbabwe p...   \n",
       "21  indian pacer mohammed shami trolled social med...   \n",
       "22  state funeral accorded veteran bollywood actre...   \n",
       "23  south korean electronics conglomerate samsung ...   \n",
       "24  bill seeks increase allotment green cards 45 c...   \n",
       "25  per reports actress sonam kapoor auction desig...   \n",
       "26  rohit sharma included team indias final xii fi...   \n",
       "27  minister state railways rajen gohain wednesday...   \n",
       "28  many 11 people killed vehicle carrying machel ...   \n",
       "29  second advisory vandalism statues ministry hom...   \n",
       "30  juventus forward cristiano ronaldo went greece...   \n",
       "31  estonia opening worlds firstever data embassy ...   \n",
       "32  cristiano ronaldo scored hattrick real madrid ...   \n",
       "33  uber wednesday said partnered nasa develop sof...   \n",
       "34  television actress saumya tandon reportedly pl...   \n",
       "35  jds supremo deve gowda asked congress treat re...   \n",
       "36  mumbai police official thursday said employee ...   \n",
       "37  microsoft ceo satya nadella wednesday said tec...   \n",
       "38  talking competition bollywood katrina kaif sai...   \n",
       "39  branch china construction bank offered chinese...   \n",
       "\n",
       "                                              summary  \\\n",
       "0   govt forms sit ryan murder case cbse seeks saf...   \n",
       "1     indrani asks furniture jewellery divorce report   \n",
       "2     ed raids 35 premises nirav modi â assets seized   \n",
       "3   japan admits 1st death 2011 fukushima nuclear ...   \n",
       "4                    entire village germany auctioned   \n",
       "5   man utd luckiest pl team liverpool unluckiest ...   \n",
       "6     raina overtakes kohli become ipls top runscorer   \n",
       "7   mumbai housing society saves â lakh month elec...   \n",
       "8   nasa launches two antarctic flights two contin...   \n",
       "9   pentagon slammed wasting â cr afghan army unif...   \n",
       "10  muslims pray outside white house protest jerus...   \n",
       "11   swimming water sports goa beaches closed monsoon   \n",
       "12               disagree term item song katrina kaif   \n",
       "13  hide marriage pregnancy anushka pregnancy rumours   \n",
       "14       remove hand cycle handle akhilesh warns cong   \n",
       "15      finch scores fastest fifty gl 7wicket win rcb   \n",
       "16   mumbai cyclone alert rumour clarifies civic body   \n",
       "17     ball century like delivery bowled womens ashes   \n",
       "18                      muslim woken azaan sonu nigam   \n",
       "19       7yearold girl raped neighbours terrace delhi   \n",
       "20  1million stolen exzimbabwe president mugabes h...   \n",
       "21  mohammed shami trolled daughters bday celebrat...   \n",
       "22    state funeral sridevi ordered maha cm rti reply   \n",
       "23   samsung plans invest 22 billion ai 5g technology   \n",
       "24  bill increase green card allotments 45 propose...   \n",
       "25          sonam auction clothes bags charity report   \n",
       "26  rohit included indias 12man squad first test v...   \n",
       "27  mumbai locals caused losses worth â crore 3 years   \n",
       "28       11 killed vehicle carrying pilgrims rolls jk   \n",
       "29  ensure prompt action statue vandalism case mha...   \n",
       "30     ronaldo leaves â tip staff greek luxury resort   \n",
       "31    estonia open worlds 1st data embassy luxembourg   \n",
       "32  ronaldo scores hattrick real madrid go 3rd la ...   \n",
       "33  uber partners nasa build flying taxi air contr...   \n",
       "34  saumya tandon quit bhabi ji ghar par hai seria...   \n",
       "35      congress treat us well forming alliance gowda   \n",
       "36  canadian woman allegedly molested 5star hotel ...   \n",
       "37         us prevent future like 1984â microsoft ceo   \n",
       "38     would insane compete 2021 yr olds katrina kaif   \n",
       "39    chinese bank offers clients dinner trump 150000   \n",
       "\n",
       "                                         pred_summary  rouge2-f  rouge2-p  \\\n",
       "0   hrd formed threemember probe murder sevenyearo...  0.000000  0.000000   \n",
       "1   jail sheena bora murder accused indrani keys s...  0.000000  0.000000   \n",
       "2   ed friday searches covering new locations frau...  0.000000  0.000000   \n",
       "3   japan acknowledged first time worker died radi...  0.000000  0.000000   \n",
       "4   entire village village germany auctioned weeke...  0.352941  0.214286   \n",
       "5   manchester united team premier league last sea...  0.000000  0.000000   \n",
       "6   raina overtakes rcb virat become alltime leadi...  0.100000  0.071429   \n",
       "7   residents <UNK> housing complex mumbai saving ...  0.100000  0.076923   \n",
       "8   first time nine years operations southern hemi...  0.000000  0.000000   \n",
       "9   us defence secy criticised spending â crore ta...  0.000000  0.000000   \n",
       "10  hundreds muslims prayed outside trump piece so...  0.000000  0.000000   \n",
       "11  swimming water sports across beaches goa close...  0.210526  0.153846   \n",
       "12  disagrees word item song girls katrina kaif sa...  0.250000  0.181818   \n",
       "13  spreading rumours something people anyway anus...  0.000000  0.000000   \n",
       "14  congress stopping cycle pollbound chhattisgarh...  0.000000  0.000000   \n",
       "15  gujarat lions defeated royal challengers 7 wic...  0.000000  0.000000   \n",
       "16  cyclone mumbai went viral social media brihanm...  0.000000  0.000000   \n",
       "17  australian womens team dismissal womens ashes ...  0.105263  0.076923   \n",
       "18  sonu nigam shares tweet muslim still woken mor...  0.125000  0.083333   \n",
       "19  sevenyearold girl raped man neighbours terrace...  0.375000  0.272727   \n",
       "20  1 million cash stolen former zimbabwe presiden...  0.000000  0.000000   \n",
       "21  pacer mohammed shami wife daughters second bir...  0.111111  0.083333   \n",
       "22  state funeral accorded veteran bollywood actre...  0.100000  0.076923   \n",
       "23  samsung plans 22 billion develop technologies ...  0.190476  0.142857   \n",
       "24  indianamerican technology professionals increa...  0.000000  0.000000   \n",
       "25  sonam auction designer outfits bags raise hung...  0.117647  0.083333   \n",
       "26  rohit sharma included team indias final test a...  0.000000  0.000000   \n",
       "27  railways suffered losses worth â crore operati...  0.285714  0.230769   \n",
       "28  11 killed vehicle carrying chenab river jammu ...  0.300000  0.214286   \n",
       "29  second advisory vandalism statues ministry hom...  0.000000  0.000000   \n",
       "30  ronaldo went greece holiday family friends por...  0.000000  0.000000   \n",
       "31  estonia opening worlds firstever data embassy ...  0.111111  0.083333   \n",
       "32  ronaldo scores hattrick real madrid moved thir...  0.363636  0.285714   \n",
       "33  uber partnered software manage air routes uber...  0.000000  0.000000   \n",
       "34  saumya tandon reportedly quit television seria...  0.100000  0.090909   \n",
       "35  jds supremo deve treat regional parties treat ...  0.111111  0.083333   \n",
       "36  mumbai police official employee molesting 35ye...  0.000000  0.000000   \n",
       "37  technology sector ensure future imagined georg...  0.000000  0.000000   \n",
       "38  would insane illogical compete 2021 years kaif...  0.210526  0.166667   \n",
       "39  branch china construction bank offers dinner u...  0.105263  0.076923   \n",
       "\n",
       "    rouge2-r  rougel-f  rougel-p  rougel-r  \n",
       "0   0.000000  0.080000  0.066667  0.100000  \n",
       "1   0.000000  0.222222  0.166667  0.333333  \n",
       "2   0.000000  0.190476  0.166667  0.222222  \n",
       "3   0.000000  0.100000  0.083333  0.125000  \n",
       "4   1.000000  0.470588  0.307692  1.000000  \n",
       "5   0.000000  0.200000  0.181818  0.222222  \n",
       "6   0.166667  0.380952  0.285714  0.571429  \n",
       "7   0.142857  0.400000  0.333333  0.500000  \n",
       "8   0.000000  0.000000  0.000000  0.000000  \n",
       "9   0.000000  0.105263  0.090909  0.125000  \n",
       "10  0.000000  0.333333  0.272727  0.428571  \n",
       "11  0.333333  0.526316  0.416667  0.714286  \n",
       "12  0.400000  0.500000  0.400000  0.666667  \n",
       "13  0.000000  0.250000  0.181818  0.400000  \n",
       "14  0.000000  0.235294  0.200000  0.285714  \n",
       "15  0.000000  0.111111  0.100000  0.125000  \n",
       "16  0.000000  0.111111  0.090909  0.142857  \n",
       "17  0.166667  0.210526  0.166667  0.285714  \n",
       "18  0.250000  0.352941  0.250000  0.600000  \n",
       "19  0.600000  0.666667  0.555556  0.833333  \n",
       "20  0.000000  0.200000  0.142857  0.333333  \n",
       "21  0.166667  0.333333  0.272727  0.428571  \n",
       "22  0.142857  0.300000  0.250000  0.375000  \n",
       "23  0.285714  0.347826  0.266667  0.500000  \n",
       "24  0.000000  0.260870  0.200000  0.375000  \n",
       "25  0.200000  0.333333  0.250000  0.500000  \n",
       "26  0.000000  0.434783  0.357143  0.555556  \n",
       "27  0.375000  0.363636  0.307692  0.444444  \n",
       "28  0.500000  0.363636  0.266667  0.571429  \n",
       "29  0.000000  0.181818  0.142857  0.250000  \n",
       "30  0.000000  0.181818  0.142857  0.250000  \n",
       "31  0.166667  0.555556  0.454545  0.714286  \n",
       "32  0.500000  0.434783  0.357143  0.555556  \n",
       "33  0.000000  0.181818  0.153846  0.222222  \n",
       "34  0.111111  0.400000  0.400000  0.400000  \n",
       "35  0.166667  0.222222  0.181818  0.285714  \n",
       "36  0.000000  0.190476  0.142857  0.285714  \n",
       "37  0.000000  0.090909  0.066667  0.142857  \n",
       "38  0.285714  0.526316  0.454545  0.625000  \n",
       "39  0.166667  0.400000  0.307692  0.571429  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset(params.test_data_path, simple_tokenizer, params.max_src_len, params.max_tgt_len, max_rows= 3200,\n",
    "                        truncate_src=True, truncate_tgt=True)\n",
    "# Prepare the validation dataset to be used in the evaluation\n",
    "print('Length Test Dataset:', len(test_dataset.pairs))\n",
    "x_test = [' '.join(pair[0]) for pair in test_dataset.pairs]\n",
    "y_test = [' '.join(pair[1]) for pair in test_dataset.pairs]\n",
    "# Predict the summaries\n",
    "#preds = generate_predictions(x_test, vocab, params, print_every=10)\n",
    "preds = get_predictions(x_test, vocab, params, print_every=100)\n",
    "# Calculate the Rouge-2 and Rouge-L metrics for the validation dataset\n",
    "r2_f, r2_p, r2_r, rl_f, rl_p, rl_r = eval_metrics(preds, y_test, False)\n",
    "print('\\nMean Rouge-2 FScore: ',np.mean(r2_f), 'Mean Rouge-L FScore: ',np.mean(rl_f))\n",
    "# Store the evaluation results to a CSV file\n",
    "test_results = save_to_df(x_test, y_test, preds, r2_f, r2_p, r2_r, rl_f, rl_p, rl_r)\n",
    "test_results.to_csv('test_results_pointer_gen.csv', index=False)\n",
    "test_results.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
